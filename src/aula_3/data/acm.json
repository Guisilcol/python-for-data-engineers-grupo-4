[{"author":"El Alaoui, Imane and Gahi, Youssef and Messoussi, Rochdi","title":"Big Data Quality Metrics for Sentiment Analysis Approaches","keywords":"Big data quality metrics, Sentiment analysis, Big data","abstract":"In a world increasingly connected, and in which information flows quickly and affects a very large number of people, sentiment analysis has seen a spectacular development over the past ten years. This is due to the fact that the explosion of social networks has allowed anyone with internet access to publicly express his opinion. Moreover, the emergence of big data has brought enormous opportunities and powerful storage and analytics tools to the field of sentiment analysis. However, big data introduces new variables and constraints that could radically affect the traditional models of sentiment analysis. Therefore, new concerns, such as big data quality, have to be addressed to get the most out of big data. To the best of our knowledge, no contributions have been published so far which address big data quality in SA throughout its different processes. In this paper, we first highlight the most important big data quality metrics to consider in any big data project. Then, we show how these metrics could be specifically considered in SA approaches and this for each phase in the big data value chain.","year":"2019","ENTRYTYPE":"inproceedings","doi":"10.1145\/3341620.3341629"},{"author":"Reda, Oumaima and Sassi, Imad and Zellou, Ahmed and Anter, Samir","title":"Towards a Data Quality Assessment in Big Data","keywords":"Data Quality, Data Quality evaluation, Big Data, Quality Models","abstract":"In recent years, as more and more data sources have become available and the volumes of data potentially accessible have increased, the assessment of data quality has taken a central role whether at the academic, professional or any other sector. Given that users are often concerned with the need to filter a large amount of data to better satisfy their requirements and needs, and that data analysis can be based on inaccurate, incomplete, ambiguous, duplicated and of poor quality, it makes everyone wonder what the results of these analyses will really be like. However, there is a very complex process involved in the identification of new, valid, potentially useful and meaningful data from a large data collection and various information systems, and is critically dependent on a number of measures to be developed to ensure data quality. To this end, the main objective of this paper is to introduce a general study on data quality related with big data, by providing what other researchers came up with on that subject. The paper will be finalized by a comparative study between the different existing data quality models.","year":"2020","ENTRYTYPE":"inproceedings","doi":"10.1145\/3419604.3419803"},{"author":"Baldassarre, Maria Teresa and Caballero, Ismael and Caivano, Danilo and Rivas Garcia, Bibiano and Piattini, Mario","title":"From Big Data to Smart Data: A Data Quality Perspective","keywords":"Data Quality, Smart Data, Big Data","abstract":"Big Data (BD) solutions are designed to better support decision-making processes in order to optimize organizational performance. These BD solutions use company\u2019s core business data, using typically large datasets. However, data that doesn\u2019t meet adequate quality levels will lead to BD solutions that will not produce useful results, and consequently may not be used to make adequate business decisions. For a long time, companies have collected and stored large amounts of data without being able to exploit the advantage of exploring it. Nowadays, and thanks to the Big Data explosion, organizations have begun to recognize the need for estimating the value of their data and, vice-versa, managing data accordingly to their value. This need of managing the Value of data has led to the concept of Smart Data. It not only involves the datasets, but also the set of technologies, tools, processes and methodologies that enable all the Values from the data to the End-users (Business, data scientist, BI\u2026). Consequently, Smart data is data actionable. We discovered that data quality is one of the most important issues when it comes to \u201csmartizing\u201d data. In this paper, we introduce a methodology to make data smarter, taking as a reference point, the quality level of the data itself.","year":"2018","ENTRYTYPE":"inproceedings","doi":"10.1145\/3281022.3281026"},{"author":"Emmanuel, Isitor and Stanier, Clare","title":"Defining Big Data","keywords":"Big Data, Big Data characteristics, Data Quality Dimensions, Data Quality","abstract":"As Big Data becomes better understood, there is a need for a comprehensive definition of Big Data to support work in fields such as data quality for Big Data. Existing definitions of Big Data define Big Data by comparison with existing, usually relational, definitions, or define Big Data in terms of data characteristics or use an approach which combines data characteristics with the Big Data environment. In this paper we examine existing definitions of Big Data and discuss the strengths and limitations of the different approaches, with particular reference to issues related to data quality in Big Data. We identify the issues presented by incomplete or inconsistent definitions. We propose an alternative definition and relate this definition to our work on quality in Big Data.","year":"2016","ENTRYTYPE":"inproceedings","doi":"10.1145\/3010089.3010090"},{"author":"Cuzzocrea, Alfredo and Sacc\\`{a}, Domenico and Ullman, Jeffrey D.","title":"Big Data: A Research Agenda","keywords":"OLAP over big data, privacy of big data, big data posting, big data","abstract":"Recently, a great deal of interest for Big Data has risen, mainly driven from a widespread number of research problems strongly related to real-life applications and systems, such as representing, modeling, processing, querying and mining massive, distributed, large-scale repositories (mostly being of unstructured nature). Inspired by this main trend, in this paper we discuss three important aspects of Big Data research, namely OLAP over Big Data, Big Data Posting, and Privacy of Big Data. We also depict future research directions, hence implicitly defining a research agenda aiming at leading future challenges in this research field.","year":"2013","ENTRYTYPE":"inproceedings","doi":"10.1145\/2513591.2527071"},{"author":"Neves, Pedro and Bernardino, Jorge","title":"Big Data Issues","keywords":"SaaS, DBMS, Big Data, PaaS, IaaS","abstract":"Big Data is a new trend regarded by both academics and business areas as an interesting concept. The paradigm includes the storage and processing of petabyte-size datasets, boosting knowledge discovery over data and providing organizations with competitive advantage over their contenders. This paper comes to provide an overview of the concept, answering questions that one has when faced with the term for the first time: What is Big Data and what are its advantages? How does it work? How is it accepted among enterprises? How to deploy a Big Data solution?","year":"2015","ENTRYTYPE":"inproceedings","doi":"10.1145\/2790755.2790785"},{"author":"Baru, Chaitan and Bhandarkar, Milind and Nambiar, Raghunath and Poess, Meikel and Rabl, Tilmann","title":"Big Data Benchmarking","keywords":"mbds","abstract":"We provide a summary of the outcomes from the Workshop on Big Data Benchmarking (WBDB2012) held on May 8-9, 2012 in San Jose, CA. The workshop discussed a number of issues related to big data benchmarking definitions and benchmark processes, and was attended by 60 invitees representing 45 different organizations from industry and academia. Attendees were selected based on their experience and expertise in one or more areas of big data, database systems, performance benchmarking, and big data applications. The participants concluded that there exists both a need and an opportunity for defining benchmarks to capture the end-to-end aspects of big data applications. The metrics for such benchmarks would need to include metrics for performance as well as price\/performance, and consider several costs including total system cost, setup cost, and energy costs. The next Workshop on Big Data Benchmarking is scheduled to be held on December 17-18, 2012 in Pune, India.","year":"2012","ENTRYTYPE":"inproceedings","doi":"10.1145\/2378356.2378368"},{"author":"Novikov, Boris and Vassilieva, Natalia and Yarygina, Anna","title":"Querying Big Data","keywords":"computer systems and technologies, query processing, query languages, big data","abstract":"The term \"Big Data\" became a buzzword and is widely used in both research and industrial worlds. Typically the concept of big data assumes a variety of different sources of information and velocity of complex analytical processing, rather than just a huge and growing volume of data. All variety, velocity, and volume create new research challenges, as nearly all techniques and tools commonly used in data processing have to be re-considered. Variety and uncertainty of big data require a mixture of exact and similarity search and grouping of complex objects based on different attributes. High-level declarative query languages are important in this context due to expressiveness and potential for optimization.In this talk we are mostly interested in an algebraic layer for complex query processing which resides between user interface (most likely, graphical) and execution engine in layered system architecture. We analyze the applicability of existing models and query languages. We describe a systematic approach to similarity handling of complex objects, simultaneous application of different similarity measures and querying paradigms, complex searching and querying, combined semi-structured and unstructured search. We introduce the adaptive abstract operations based on the concept of fuzzy set, which are needed to support uniform handling of different kinds of similarity processing. To ensure an efficient implementation, approximate algorithms with controlled quality are required to enable quality versus performance trade-off for timeliness of similarity processing. Uniform and adaptive operations enable high-level declarative definition of complex queries and provide options for optimization.","year":"2012","ENTRYTYPE":"inproceedings","doi":"10.1145\/2383276.2383278"},{"author":"Dong, Xin Luna and Srivastava, Divesh","title":"Big Data Integration","keywords":null,"abstract":"The Big Data era is upon us: data is being generated, collected and analyzed at an unprecedented scale, and data-driven decision making is sweeping through society. Since the value of data explodes when it can be linked and fused with other data, addressing the big data integration (BDI) challenge is critical to realizing the promise of Big Data.BDI differs from traditional data integration in many dimensions: (i) the number of data sources, even for a single domain, has grown to be in the tens of thousands, (ii) many of the data sources are very dynamic, as a huge amount of newly collected data are continuously made available, (iii) the data sources are extremely heterogeneous in their structure, with considerable variety even for substantially similar entities, and (iv) the data sources are of widely differing qualities, with significant differences in the coverage, accuracy and timeliness of data provided. This tutorial explores the progress that has been made by the data integration community on the topics of schema mapping, record linkage and data fusion in addressing these novel challenges faced by big data integration, and identifies a range of open problems for the community.","year":"2013","ENTRYTYPE":"article","doi":"10.14778\/2536222.2536253"},{"author":"Benjamins, V. Richard","title":"Big Data: From Hype to Reality?","keywords":"Analytics, Business, Big Data","abstract":"The traditional world of relational databases and enterprise data warehouses is being challenged by growth in data volumes, the rise of unstructured and semi-structured data, and the desire to extract more valuable business insights. In order to remain competitive: we are entering the world of 'BIG DATA'. Scale-out, commodity hardware-based solutions based on the map-reduce programming model for parallel processing on large hardware are emerging to address these BIG DATA requirements that have challenged traditional technologies. The focus of this talk is on the potential business value to be created in this area by describing the opportunities and risks arising from the recent emergence of BIG DATA Analytics technology for companies. The role businesses can play in BIG DATA is also under discussion, and finally Telefonica's experience is explained in applying BIG DATA technology, both internally for enhancement of its own business processes and externally, where we are applying the technology to benefit our customers directly.","year":"2014","ENTRYTYPE":"inproceedings","doi":"10.1145\/2611040.2611042"},{"author":"Gross, Thomas","title":"Big Data: Little Software?","keywords":null,"abstract":"The steps of accessing, storing, and transmitting \"Big Data\" raise many interesting problems. But big data sets also amplify any system or software inefficiencies when large data sets require processing. So the efficiency of the generate code (and the runtime system) is crucial if we want to see widespread use of applications based on big data.Adaptive software exploits platform and data properties to custom-tailor program executions to the current environment. However, modern platforms have many features that make it difficult to support adaptive software. Multi-core systems with a non-uniform memory architecture expose various asymmetries and complicate the runtime system's task of data management, yet even modest multi-processors exhibit NUMA properties. Processor features like prefetchers are difficult to model by a compiler and may influence the execution in unexpected ways. Finally, performance monitoring units are supposed to allow a (just-in-time) compiler to obtain the information needed to adapt the generated code. But current performance monitoring units are incomplete and, worse, subject to change over time. An adaptive software system needs performance data that is readily available, reliable, and stable.In this talk I will discuss our experiences in modeling modern systems and argue for portable performance monitoring units that allow higher levels of the software tool chain to rely on live performance data.","year":"2013","ENTRYTYPE":"inproceedings","doi":"10.1145\/2485732.2485757"},{"author":"Johnson, Jeffrey and Denning, Peter and Delic, Kemal A. and Sousa-Rodrigues, David","title":"Big Data: Big Data or Big Brother? That is the Question Now.","keywords":null,"abstract":"This ACM Ubiquity Symposium presented some of the current thinking about big data developments across four topical dimensions: social, technological, application, and educational. While 10 articles can hardly touch the expanse of the field, we have sought to cover the most important issues and provide useful insights for the curious reader. More than two dozen authors from academia and industry provided shared their points of view, their current focus of interest and their outlines of future research. Big digital data has changed and will change the world in many ways. It will bring some big benefits in the future, but combined with big AI and big IoT devices creates several big challenges. These must be carefully addressed and properly resolved for the future benefit of humanity.","year":"2018","ENTRYTYPE":"article","doi":"10.1145\/3158352"},{"author":"Lukesh, Susan S.","title":"Big Data","keywords":null,"abstract":null,"year":"2014","ENTRYTYPE":"article","doi":"10.1145\/2614512.2629588"},{"author":"Cron, Andrew and Nguyen, Huy L. and Parameswaran, Aditya","title":"Big Data","keywords":null,"abstract":null,"year":"2012","ENTRYTYPE":"article","doi":"10.1145\/2331042.2331045"},{"author":"CACM Staff","title":"Big Data","keywords":null,"abstract":null,"year":"2017","ENTRYTYPE":"article","doi":"10.1145\/3079064"},{"author":"Srivastava, Divesh","title":"Big Data Integration","keywords":null,"abstract":"The Big Data era is upon us: data is being generated, collected and analyzed at an unprecedented scale, and data-driven decision making is sweeping through all aspects of society. Since the value of data explodes when it can be linked and fused with other data, addressing the big data integration (BDI) challenge is critical to realizing the promise of Big Data. BDI differs from traditional data integration in many dimensions: (i) the number of data sources, even for a single domain, has grown to be in the tens of thousands, (ii) many of the data sources are very dynamic, as a huge amount of newly collected data are continuously made available, (iii) the data sources are extremely heterogeneous in their structure, with considerable variety even for substantially similar entities, and (iv) the data sources are of widely differing qualities, with significant differences in the coverage, accuracy and timeliness of data provided. This talk explores the progress that has been made by the data integration community in addressing these novel challenges faced by big data integration, and identifies a range of open problems for the community.","year":"2013","ENTRYTYPE":"inproceedings","doi":null},{"author":"Ramachandra, Karthik and Sudarshan, S.","title":"Big Data: From Querying to Transaction Processing","keywords":null,"abstract":"The term Big Data has been used and abused extensively in the past few years, and means different things to different people. A commonly used notion says Big Data is about \"volume\" (of data), \"velocity\" (rate at which data is inserted\/updated) and \"variety\" (of data types). In this tutorial, we use the term Big Data to refer to any data processing need that requires a high degree of parallelism. In other words, we focus primarily on the \"volume\" and \"velocity\" aspects.As part of this tutorial, we will cover some aspects of Big Data management, in particular scalable storage, scalable query processing, and scalable transaction processing.This is an introductory tutorial for those who are not familiar with the areas that we will be covering. The focus will be conceptual; it is not meant as a tutorial on how to use any specific system.","year":"2013","ENTRYTYPE":"inproceedings","doi":null},{"author":"Masabo, Emmanuel and Kaawaase, Kyanda Swaib and Sansa-Otim, Julianne","title":"Big Data: Deep Learning for Detecting Malware","keywords":"machine learning, malware detection, big data analytics, deep learning","abstract":"Malicious software, commonly known as malware are constantly getting smarter with the capabilities of undergoing self-modifications. They are produced in big numbers and widely deployed very fast through the Internet-capable devices. This is therefore a big data problem and remains challenging in the research community. Existing detection methods should be enhanced in order to effectively deal with today's malware. In this paper, we propose a novel real-time monitoring, analysis and detection approach that is achieved by applying big data analytics and machine learning in the development of a general detection model. The learnings achieved through big data render machine learning more efficient. Using the deep learning approach, we designed and developed a scalable detection model that brings improvement to the existing solutions. Our experiments achieved an accuracy of 97% and ROC of 0.99.","year":"2018","ENTRYTYPE":"inproceedings","doi":"10.1145\/3195528.3195533"},{"author":"Davoudian, Ali and Liu, Mengchi","title":"Big Data Systems: A Software Engineering Perspective","keywords":"Big Data systems, Big Data, requirements engineering, software reference architecture, quality assurance, software engineering","abstract":"Big Data Systems (BDSs) are an emerging class of scalable software technologies whereby massive amounts of heterogeneous data are gathered from multiple sources, managed, analyzed (in batch, stream or hybrid fashion), and served to end-users and external applications. Such systems pose specific challenges in all phases of software development lifecycle and might become very complex by evolving data, technologies, and target value over time. Consequently, many organizations and enterprises have found it difficult to adopt BDSs. In this article, we provide insight into three major activities of software engineering in the context of BDSs as well as the choices made to tackle them regarding state-of-the-art research and industry efforts. These activities include the engineering of requirements, designing and constructing software to meet the specified requirements, and software\/data quality assurance. We also disclose some open challenges of developing effective BDSs, which need attention from both researchers and practitioners.","year":"2020","ENTRYTYPE":"article","doi":"10.1145\/3408314"},{"author":"Mani, Murali and Fei, Si","title":"Effective Big Data Visualization","keywords":"Big Data, Data Visualization, Data Analytics","abstract":"In the last several years, big data analytics has found an increasing role in our everyday lives. Data visualization has long been accepted as an integral part of data analytics. However, data visualization systems are not equipped to handle the complexities typically found in big data. Our work examines effective ways of visualizing big data, while also realizing that most visualization processes are interactive. During an interactive visualization session, an analyst issues several visualization requests, each of which builds on prior visualizations. In our approach, we integrate a distributed data processing system that can effectively process big data with a visualization system that can provide effective interactive visualization but for smaller amounts of data. The analyst's current request is used to infer contextual information about the analyst such as their expertise and tolerance for delay. This information is used to carefully determine additional data that can be sent to the visualization system for decreasing the response time for future requests, thus providing a better experience for the analyst and increasing their productivity.","year":"2017","ENTRYTYPE":"inproceedings","doi":"10.1145\/3105831.3105857"},{"author":"Fan, Wenfei","title":"Data Quality: From Theory to Practice","keywords":null,"abstract":"Data quantity and data quality, like two sides of a coin, are equally important to data management. This paper provides an overview of recent advances in the study of data quality, from theory to practice. We also address challenges introduced by big data to data quality management.","year":"2015","ENTRYTYPE":"article","doi":"10.1145\/2854006.2854008"},{"author":"Pflugfelder, Ehren Helmut","title":"Big Data, Big Questions","keywords":null,"abstract":"One significant concern I have for the future of technical communication, a concern I often share with my students, involves the impact of \"big data.\" Though the term is frequently used with a sneer, or at least a slightly unsettled laugh, the methods for retrieving information from large data sets are improving as I write this. One significant question the field faces is: \"what new relationships will develop and what new work will technical communicators be responsible for in emergent big data projects, in coming years?\"","year":"2013","ENTRYTYPE":"article","doi":"10.1145\/2524248.2524253"},{"author":"Castelluccia, Daniela and Caldarola, Enrico G. and Boffoli, Nicola","title":"Environmental Big Data: A Systematic Mapping Study","keywords":"Data Management, Systematic Mapping, Big Data, Environment, Data Integration","abstract":"Big data sets and analytics are increasingly being used by government agencies, non-governmental organizations, and privatecompanies to forward environmental protection. Improving energy efficiency, promoting environmental justice, tracking climate change, and monitoring water quality are just a few of the objectives being furthered by the use of Big Data. The authors provide a more detailed analysis of the emerging evidence-based insights on Environmental Big Data (EBD), by applying the well-defined method of systematic mapping. The analysis of results throws light on the current open issues of Environmental Big Data. Moreover, different facets of the study can be combined nto answer more specific research questions. The report reveals the need for more empirical research able to provide new metrics measuring efficiency and effectiveness of the proposed analytics and new methods and tools supporting data processing workflow in EBD","year":"2017","ENTRYTYPE":"article","doi":"10.1145\/3011286.3011307"},{"author":"Abell\\'{o}, Alberto","title":"Big Data Design","keywords":"nosql, database design, big data","abstract":"It is widely accepted today that Relational databases are not appropriate in highly distributed shared-nothing architectures of commodity hardware, that need to handle poorly structured heterogeneous data. This has brought the blooming of NoSQL systems with the purpose of mitigating such problem, specially in the presence of analytical workloads. Thus, the change in the data model and the new analytical needs beyond OLAP take us to rethink methods and models to design and manage these newborn repositories. In this paper, we will analyze state of the art and future research directions.","year":"2015","ENTRYTYPE":"inproceedings","doi":"10.1145\/2811222.2811235"},{"author":"Zhou, Ming and Cao, Menglin and Park, Taeho and Pyeon, Jae-Ho","title":"Clarifying Big Data: The Concept and Its Applications","keywords":null,"abstract":"This paper clarifies the concept of Big Data with a discussion of its managerial implications and presents its defining characteristics differentiating Big Data with traditional analytics. This paper also introduces the concept of Big Data in the context of three industries, namely, finance, supply chain and marketing and discusses how this concept can be applied in the business world. With regard to this concept, fundamental yet critical discussions were made for any further understanding of Big Data. Finally, this paper contributes to our current knowledge of Big Data by relating and contrasting Big Data to traditional analysis while presenting context specific discussions for its applications. Although technical aspects of Big Data were not covered in this paper, this paper focused on serving as a business discussion for the concept of Big Data. For future work, business contents must be related to technical capabilities and solutions in order to provide a better understanding of Big Data.","year":"2015","ENTRYTYPE":"inproceedings","doi":"10.1145\/2837060.2837068"},{"author":"Mockus, Audris","title":"Engineering Big Data Solutions","keywords":"Data Engineering, Operational Data, Game Theory, Statistics, Data Quality, Analytics, Data Science","abstract":"Structured and unstructured data in operational support tools have long been prevalent in software engineering. Similar data is now becoming widely available in other domains. Software systems that utilize such operational data (OD) to help with software design and maintenance activities are increasingly being built despite the difficulties of drawing valid conclusions from disparate and low-quality data and the continuing evolution of operational support tools. This paper proposes systematizing approaches to the engineering of OD-based systems. To prioritize and structure research areas we consider historic developments, such as big data hype; synthesize defining features of OD, such as confounded measures and unobserved context; and discuss emerging new applications, such as diverse and large OD collections and extremely short development intervals. To sustain the credibility of OD-based systems more research will be needed to investigate effective existing approaches and to synthesize novel, OD-specific engineering principles.","year":"2014","ENTRYTYPE":"inproceedings","doi":"10.1145\/2593882.2593889"},{"author":"Statchuk, Craig and Iles, Michael and Thomas, Fenny","title":"Big Data and Analytics","keywords":null,"abstract":"Business Analytics is maturing and moving towards mass adoption. The emergence of big data increases the need for innovative tools and methodologies. Of particular interest is the established Business Intelligence market segment, built on structured data and reporting. How does big data affect methodologies like ETL, modeling and report authoring? Business Intelligence is at a crossroads between less formal data analysis at scale and business imperatives like regulatory reporting that runs an enterprise. This paper highlights new technologies and services that move the methodologies of old into the data-centric world of high volume and velocity that defines the modern information landscape.","year":"2013","ENTRYTYPE":"inproceedings","doi":null},{"author":"Hepworth, Katherine","title":"Big Data Visualization: Promises &amp; Pitfalls","keywords":null,"abstract":"A few weeks ago, I was having dinner with a friend when a controversial subject came up. My friend had an extremely strong opinion about the harm caused by vaccination, and his argument went something like this: \"I've seen the data. There was an infographic laying it all out.\" He couldn't remember specific numbers from the visualization he'd seen or the author of the article. He couldn't even remember the name of the publication, but the data visualization's overall argument was firmly lodged in his mind. His situation is not unique, and it provides telling insights on how we, as humans, perceive and respond to big data visualization.","year":"2017","ENTRYTYPE":"article","doi":"10.1145\/3071088.3071090"},{"author":"Broder, Andrei and Adamic, Lada and Franklin, Michael and Rijke, Maarten de and Xing, Eric and Yu, Kai","title":"Big Data: New Paradigm or \"Sound and Fury, Signifying Nothing\"?","keywords":"big data","abstract":"The Gartner's 2014 Hype Cycle released last August moves Big Data technology from the Peak of Inflated Expectations to the beginning of the Trough of Disillusionment when interest starts to wane as reality does not live up to previous promises. As the hype is starting to dissipate it is worth asking what Big Data (however defined) means from a scientific perspective: Did the emergence of gigantic corpora exposed the limits of classical information retrieval and data mining and led to new concepts and challenges, the way say, the study of electromagnetism showed the limits of Newtonian mechanics and led to Relativity Theory, or is it all just \"sound and fury, signifying nothing\", simply a matter of scaling up well understood technologies? To answer this question, we have assembled a distinguished panel of eminent scientists, from both Industry and Academia: Lada Adamic (Facebook), Michael Franklin (University of California at Berkeley), Maarten de Rijke (University of Amsterdam), Eric Xing (Carnegie Mellon University), and Kai Yu (Baidu) will share their point of view and take questions from the moderator and the audience.","year":"2015","ENTRYTYPE":"inproceedings","doi":"10.1145\/2684822.2697027"},{"author":"Giles, C. Lee","title":"Scholarly Big Data: Information Extraction and Data Mining","keywords":"digital libraries, data mining, information retrieval, big data, information extraction, entity resolution","abstract":"Collections of scholarly documents are usually not thought of as big data. However, large collections of scholarly documents often have many millions of publications, authors, citations, equations, figures, etc., and large scale related data and structures such as social networks, slides, data sets, etc. We discuss scholarly big data challenges, insights, methodologies and applications. We illustrate scholarly big data issues with examples of specialized search engines and recommendation systems that use information extraction and data mining in various areas such as computer science, chemistry, archaeology, acknowledgements, reference recommendation, collaboration recommendation, and others.","year":"2013","ENTRYTYPE":"inproceedings","doi":"10.1145\/2505515.2527109"},{"author":"Menon, Aravind","title":"Big Data @ Facebook","keywords":"mbds","abstract":"The Facebook Data Infrastructure supports a wide range of applications, including both external facing products and services and internal applications. This paper focuses on the Data Warehousing and Analytics platform of Facebook that provides support for batch-oriented analytics applications. Facebook's data infrastructure is built largely on top of open-source technologies such as Apache Hadoop, HDFS, MapReduce and Hive, and provides a rich set of tools for different users to perform analytics queries on Facebook data. As the Facebook user base continues to grow, we continue to enhance our data platform in order to deal with the challenges of scaling with increasing amounts of data.","year":"2012","ENTRYTYPE":"inproceedings","doi":"10.1145\/2378356.2378364"},{"author":"Kechadi, M-Tahar","title":"Healthcare Big Data: Challenges and Opportunities","keywords":"Big data, Ecosystems, Data Mining, Sensor Data, System Design, Healthcare Data, Data Analytics","abstract":"In healthcare sector huge quantities of data about patients and their medical conditions have been gathered through clinical databases and various other healthcare processes. Currently, it records nearly all aspects of care, including patient personal information, clinical trials, hospital records, diagnosis, medication, test results, imaging data, costs, administrative reports, etc. Like in other application domains, the big data revolution holds also great promise in the area of healthcare, as the available data about individual patients is very rich, and hides crucial knowledge that can be exploited to improve patients' care while reducing its cost. For instance, in 2012 worldwide collected healthcare data was estimated to be in the region of 500 petabytes and it is expected to grow 50 times more in 2020 (25 Exabytes). Turning this massive amount of data into knowledge that can be used to identify needs, predict and prevent critical patients' conditions, and help practitioners to make rapid and accurate decisions is not only a desire but is of urgent and crucial necessity. Therefore, healthcare organisations must have the ability to manage and analyse their data in a rapid and efficient manner to answer several critical questions related to diseases, treatments, patients' behaviours, and care management. However, building such system faces huge challenges: 1) data complexity, 2) Privacy, security, ethical, legal, and social issues, and 3) Interoperability, portability, and compatibility. We will discuss all these challenges and the requirements of healthcare ecosystem. This will lead us to describe some innovative methodologies of how to build such ecosystem to face the healthcare challenges of the next decade or so.","year":"2016","ENTRYTYPE":"inproceedings","doi":"10.1145\/3010089.3010143"},{"author":"Ianni, Michele and Masciari, Elio and Mazzeo, Giuseppe M. and Zaniolo, Carlo","title":"Efficient Big Data Clustering","keywords":"Spark, Clustering, Big Data","abstract":"The need to support advanced analytics on Big Data is driving data scientist' interest toward massively parallel distributed systems and software platforms, such as Map-Reduce and Spark, that make possible their scalable utilization. However, when complex data mining algorithms are required, their fully scalable deployment on such platforms faces a number of technical challenges that grow with the complexity of the algorithms involved. Thus algorithms, that were originally designed for a sequential nature, must often be redesigned in order to effectively use the distributed computational resources. In this paper, we explore these problems, and then propose a solution which has proven to be very effective on the complex hierarchical clustering algorithm CLUBS+. By using four stages of successive refinements, CLUBS+ delivers high-quality clusters of data grouped around their centroids, working in a totally unsupervised fashion. Experimental results confirm the accuracy and scalability of CLUBS+.","year":"2018","ENTRYTYPE":"inproceedings","doi":"10.1145\/3216122.3216154"},{"author":"Pouyanfar, Samira and Yang, Yimin and Chen, Shu-Ching and Shyu, Mei-Ling and Iyengar, S. S.","title":"Multimedia Big Data Analytics: A Survey","keywords":"Big data analytics, 5V challenges, multimedia databases, multimedia analysis, machine learning, survey, retrieval, mobile multimedia, indexing, data mining","abstract":"With the proliferation of online services and mobile technologies, the world has stepped into a multimedia big data era. A vast amount of research work has been done in the multimedia area, targeting different aspects of big data analytics, such as the capture, storage, indexing, mining, and retrieval of multimedia big data. However, very few research work provides a complete survey of the whole pine-line of the multimedia big data analytics, including the management and analysis of the large amount of data, the challenges and opportunities, and the promising research directions. To serve this purpose, we present this survey, which conducts a comprehensive overview of the state-of-the-art research work on multimedia big data analytics. It also aims to bridge the gap between multimedia challenges and big data solutions by providing the current big data frameworks, their applications in multimedia analyses, the strengths and limitations of the existing methods, and the potential future directions in multimedia big data analytics. To the best of our knowledge, this is the first survey that targets the most recent multimedia management techniques for very large-scale data and also provides the research studies and technologies advancing the multimedia analyses in this big data era.","year":"2018","ENTRYTYPE":"article","doi":"10.1145\/3150226"},{"author":"Miao, Xin","title":"Big Data and Smart Grid","keywords":"Smart Grid, privacy protection, data exploration, architecture, safety, Big Data, power consumption","abstract":"Big Data brings the challenge for Smart Grid. By using the method of SWOT, the double-edged sword effect of Big Data for the Smart Grid has been analyzed. Big Data provides both opportunities and challenges. The benefits and opportunities are which, Big Data bringing data view, changing thinking methods and tools, expanding the application scene, providing better service to the society, enhancing the value of the opportunity. At the same time, Big Data will lead to the challenges in Smart Grid, for example, because of security challenges of Big Data itself, Big Data more concentrated, cause safety challenges in Smart Grid is more serious; the energy consumption challenges of Big Data; Big Data privacy threat Smart Grid. From the viewpoint of information theory of Shannon, the following conclusions can be reached: the electric power consumption is positively correlated closely with the volume of Big Data; the energy consumption of data grows exponentially.","year":"2014","ENTRYTYPE":"inproceedings","doi":"10.1145\/2640087.2644175"},{"author":"Mohammad, Atif and Mcheick, Hamid and Grant, Emanuel","title":"Big Data Architecture Evolution: 2014 and Beyond","keywords":"cloud computing, big data","abstract":"This paper aims at developing the Big Data Architecture, and its relation with Analytics, Cloud Services as well as Business Intelligence. The chief aim from all mentioned is to enable the Enterprise Architecture and the Vision of an Organizational target to utilize all the data they are ingesting and regressing data for their short-term or long-terms analytical needs, while making sure that they are addressing during the design phase of such data architecture for both directly and indirectly related stakeholder. Since all stakeholders have their relative interests to utilize the transformed data-sets. This paper also identifies most of the Big Data Architecture, threat analysis within a Big Data System and Big Data Analytic Roadmaps, in terms of smaller components by conducting a gap-analysis that has significant importance as Baseline Big Data Architecture, targeting the end resultant Architectures, once the distillation process of main Big Data Architecture is completed by the Data Architects.","year":"2014","ENTRYTYPE":"inproceedings","doi":"10.1145\/2656346.2656358"},{"author":"Thuraisingham, Bhavani","title":"Big Data Security and Privacy","keywords":"privacy, security, big data","abstract":"This paper describes the issues surrounding big data security and privacy and provides a summary of the National Science Foundation sponsored workshop on this topic held in Dallas, Texas on September 16-17, 2014. Our goal is to build a community in big data security and privacy to explore the challenging research problems.","year":"2015","ENTRYTYPE":"inproceedings","doi":"10.1145\/2699026.2699136"},{"author":"Sultan, Kashif and Ali, Hazrat","title":"Where Big Data Meets 5G?","keywords":"mobile communication, 5G networks, data analtyics, big data","abstract":"Due to massive increase in data collection from wireless devices, wireless sensor networks, and network operators, data processing has become a challenge. The massive data can broadly be categorized into raw data and right data. Future generation network (5G) can be optimized if right data is extracted efficiently from such a massive raw data. Such a solution is provided through big data analytics. In this article, we discuss big data analytics solution for 5G network. We also outline existing big data architectures proposed for the network optimization. We propose a generalized flow structure for big data based analytics in 5G. Finally, we summarize our article by highlighting some challenges for big data analytics in 5G.","year":"2017","ENTRYTYPE":"inproceedings","doi":"10.1145\/3018896.3025151"},{"author":"Miloslavskaya, Natalia and Senatorov, Mikhail and Tolstoy, Alexander and Zapechnikov, Sergey","title":"Big Data Information Security Maintenance","keywords":"Secure Infrastructure, Big Data, Information Security","abstract":"The need to protect big data, particularly those relating to information security maintenance (ISM) of an enterprise's IT infrastructure (ITI), and their processing is shown. Related worldwide experience of addressing big data ISM issues is summarized. An attempt to formulate a big data ISM problem statement is undertaken. An infrastructure for big data ISM is proposed. The importance of big data visualization is discussed.","year":"2014","ENTRYTYPE":"inproceedings","doi":"10.1145\/2659651.2659655"},{"author":"Endert, Alex and Szymczak, Samantha and Gunning, Dave and Gersh, John","title":"Modeling in Big Data Environments","keywords":null,"abstract":"Human-Centered Big Data Research (HCBDR) is an area of work that focuses on the methodologies and research areas focused on understanding how humans interact with \"big data\". In the context of this paper, we refer to \"big data\" in a holistic sense, including most (if not all) the dimensions defining the term, such as complexity, variety, velocity, veracity, etc. Simply put, big data requires us as researchers of to question and reconsider existing approaches, with the opportunity to illuminate new kinds of insights that were traditionally out of reach to humans.","year":"2014","ENTRYTYPE":"inproceedings","doi":"10.1145\/2609876.2609890"},{"author":"Cuzzocrea, Alfredo and Damiani, Ernesto","title":"Pedigree-Ing Your Big Data: Data-Driven Big Data Privacy in Distributed Environments","keywords":null,"abstract":"This paper introduces a general framework for supporting data-driven privacy-preserving big data management in distributed environments, such as emerging Cloud settings. The proposed framework can be viewed as an alternative to classical approaches where the privacy of big data is ensured via security-inspired protocols that check several (protocol) layers in order to achieve the desired privacy. Unfortunately, this injects considerable computational overheads in the overall process, thus introducing relevant challenges to be considered. Our approach instead tries to recognize the \"pedigree\" of suitable summary data representatives computed on top of the target big data repositories, hence avoiding computational overheads due to protocol checking. We also provide a relevant realization of the framework above, the so-called Data-dRIven aggregate-PROvenance privacy-preserving big Multidimensional data (DRIPROM) framework, which specifically considers multidimensional data as the case of interest.","year":"2018","ENTRYTYPE":"inproceedings","doi":"10.1109\/CCGRID.2018.00100"},{"author":"Argenta, Chris and Benson, Jordan and Bos, Nathan and Paletz, Susannah B. F. and Pike, William and Wilson, Aaron","title":"Sensemaking in Big Data Environments","keywords":null,"abstract":"We report on the sensemaking breakout group at the Human Centered Big Data Research (HCBDR-2014) workshop. The authors are a multi-disciplinary team of invited researchers and stakeholders who participated in this breakout session. This report includes an overview of our discussions on the many research challenges associated with sensemaking within a big data environment. Specifically, we focused on key topics that fit squarely in the intersection of the sensemaking and big data research, as other communities already exist for decision making and big data technologies independently. As part of this effort, our group developed and proposed a framework around which this community can target and structure future research. This framework is intended to allow the community to systematically identify areas where innovative research might make large contributions to sensemaking in a big data environment.","year":"2014","ENTRYTYPE":"inproceedings","doi":"10.1145\/2609876.2609889"},{"author":"Gopalkrishnan, Vivekanand and Steier, David and Lewis, Harvey and Guszcza, James","title":"Big Data, Big Business: Bridging the Gap","keywords":null,"abstract":"Business analytics, occupying the intersection of the worlds of management science, computer science and statistical science, is a potent force for innovation in both the private and public sectors. The successes of business analytics in strategy, process optimization and competitive advantage has led to data being increasingly recognized as a valuable asset in many organizations. In recent years, thanks to a dramatic increase in the volume, variety and velocity of data, the loosely defined concept of \"Big Data\" has emerged as a topic of discussion in its own right -- with different viewpoints in both the business and technical worlds. From our perspective, it is important for discussions of \"Big Data\" to start from a well-defined business goal, and remain moored to fundamental principles of both cost\/benefit analysis as well as core statistical science. This note discusses some business case considerations for analytics projects involving \"Big Data\", and proposes key questions that businesses should ask. With practical lessons from Big Data deployments in business, we also pose a number of research challenges that may be addressed to enable the business analytics community bring best data analytic practices when confronted with massive data sets.","year":"2012","ENTRYTYPE":"inproceedings","doi":"10.1145\/2351316.2351318"},{"author":"Villanustre, Flavio","title":"Industrial Big Data Analytics: Lessons from the Trenches","keywords":"distributed algorithms, declarative programming, dataflow programming, big data, abstraction models","abstract":"Big Data Analytics in particular and Data Science in general have become key disciplines in the last decade. The convergence of Information Technology, Statistics and Mathematics, to explore and extract information from Big Data have challenged the way many industries used to operate, shifting the decision making process in many organizations. A new breed of Big Data platforms has appeared, to fulfill the needs to process data that is large, complex, variable and rapidly generated. The author describes the experience in this field from a company that provides Big Data analytics as its core business.","year":"2015","ENTRYTYPE":"inproceedings","doi":null},{"author":"Villa, Adam H.","title":"Big Data: Motivating the Development of an Advanced Database Systems Course","keywords":null,"abstract":"The creation of massive data sets, commonly referred to as Big Data, has motivated the development of new database systems and techniques for managing, monitoring, querying, and analyzing data [5]. As data sizes grow, so do the technologies developed to the meet this new demand, which in turn generates new employment opportunities for graduating students. Preparing students for these new positions requires the integration of these new techniques and methodologies into the curriculum. The growth of Big Data is motivating the development of advanced database courses. This paper presents an approach to creating such a course using flexible modules.","year":"2016","ENTRYTYPE":"article","doi":null},{"author":"Kantarcioglu, Murat","title":"Securing Big Data: New Access Control Challenges and Approaches","keywords":"encrypted data processing, nosql databases, intrusion detection, access control, privacy, security","abstract":"Recent cyber attacks have shown that the leakage\/stealing of big data may result in enormous monetary loss and damage to organizational reputation, and increased identity theft risks for individuals. Furthermore, in the age of big data, protecting the security and privacy of stored data is paramount for maintaining public trust, and getting the full value from the collected data. In this talk, we first discuss the unique security and privacy challenges arise due to big data and the NoSQL systems designed to analyze big data. Also we discuss our proposed SecureDL system that is built on top of existing NoSQL databases such as Hadoop and Spark and designed as a data access broker where each request submitted by a user app is automatically captured. These captured requests are logged, analyzed and then modified (if needed) to conform with security and privacy policies (e.g.,[5]), and submitted to underlying NoSQL database. Furthermore, SecureDL can allow organizations to audit their big data usage to prevent data misuse and comply with various privacy regulations[2]. SecureDL is totally transparent from the user point of view and does not require any change to the user's code and\/or the underlying NoSQL database systems. Therefore, it can be deployed on existing NoSQL databases.Later on, we discuss how to add additional security layer for protecting big data using encryption techniques (e.g., [1, 3, 4]). Especially, we discuss our work on leveraging the modern hardware based trusted execution environments (TEEs) such as Intel SGX for secure encrypted data processing. We also discuss how to provide a simple, secure and high level language based framework that is suitable for enabling generic data analytics for non-security experts who do not have security concepts such as \"oblivious execution''. Our proposed framework allows data scientists to perform the data analytic tasks with TEEs using a Python\/Matlab like high level language; and automatically compiles programs written in our language to optimal execution code by managing issues such as optimal data block sizes for I\/O, vectorized computations to simplify much of the data processing, and optimal ordering of operations for certain tasks. Using these design choices, we show how to provide guarantees for efficient and secure big data analytics over encrypted data.","year":"2019","ENTRYTYPE":"inproceedings","doi":"10.1145\/3322431.3326330"},{"author":"Tahsin, Anika and Hasan, Md. Manzurul","title":"Big Data &amp; Data Science: A Descriptive Research on Big Data Evolution and a Proposed Combined Platform by Integrating R and Python on Hadoop for Big Data Analytics and Visualization","keywords":"Data Science, R, Python, Big Data, Hadoop","abstract":"In this technological era, Big Data is a new glorified term in where Data Science is the secret sauce of it. Undoubtedly, the digitalization of data is not the whole story; it is just a beginning of Data Science area of study. There was a time when the main focus was on building framework and processing of this data. After Hadoop HDFS and MapReduce resolved this issue already typically the concentration will follow to the next level. In terms of this, Big Data on Data Science becoming the most hyped solving area. At the moment of zettabytes data, R, Python, Hadoop all are in progressing phase in where integration among individual framework and tools will be highlighted and newest data handling tools are integrating with latest technology in terms of analytics competence. There will be a positivity when this integration will expose a new horizon for researchers and develop the preeminent solution based on the challenges.","year":"2020","ENTRYTYPE":"inproceedings","doi":"10.1145\/3377049.3377051"},{"author":"De Francisci Morales, Gianmarco and Bifet, Albert and Khan, Latifur and Gama, Joao and Fan, Wei","title":"IoT Big Data Stream Mining","keywords":"IoT, data streams, big data, data science","abstract":"The challenge of deriving insights from the Internet of Things (IoT) has been recognized as one of the most exciting and key opportunities for both academia and industry. Advanced analysis of big data streams from sensors and devices is bound to become a key area of data mining research as the number of applications requiring such processing increases. Dealing with the evolution over time of such data streams, i.e., with concepts that drift or change completely, is one of the core issues in IoT stream mining. This tutorial is a gentle introduction to mining IoT big data streams. The first part introduces data stream learners for classification, regression, clustering, and frequent pattern mining. The second part deals with scalability issues inherent in IoT applications, and discusses how to mine data streams on distributed engines such as Spark, Flink, Storm, and Samza.","year":"2016","ENTRYTYPE":"inproceedings","doi":"10.1145\/2939672.2945385"},{"author":"Yang, Tianbao and Lin, Qihang and Jin, Rong","title":"Big Data Analytics: Optimization and Randomization","keywords":"optimization, randomized approximation, machine learning, randomized reduction","abstract":"As the scale and dimensionality of data continue to grow in many applications of data analytics (e.g., bioinformatics, finance, computer vision, medical informatics), it becomes critical to develop efficient and effective algorithms to solve numerous machine learning and data mining problems. This tutorial will focus on simple yet practically effective techniques and algorithms for big data analytics. In the first part, we plan to present the state-of-the-art large-scale optimization algorithms, including various stochastic gradient descent methods, stochastic coordinate descent methods and distributed optimization algorithms, for solving various machine learning problems. In the second part, we will focus on randomized approximation algorithms for learning from large-scale data. We will discuss i) randomized algorithms for low-rank matrix approximation; ii) approximation techniques for solving kernel learning problems; iii) randomized reduction methods for addressing the high-dimensional challenge. Along with the description of algorithms, we will also present some empirical results to facilitate understanding of different algorithms and comparison between them.","year":"2015","ENTRYTYPE":"inproceedings","doi":"10.1145\/2783258.2789989"},{"author":"Heer, Jeffrey and Kandel, Sean","title":"Interactive Analysis of Big Data","keywords":null,"abstract":"New user interfaces can transform how we work with big data, and raise exciting research problems that span human-computer interaction, machine learning, and distributed systems.","year":"2012","ENTRYTYPE":"article","doi":"10.1145\/2331042.2331058"}]